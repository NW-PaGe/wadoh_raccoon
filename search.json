[
  {
    "objectID": "reference/index.html",
    "href": "reference/index.html",
    "title": "Function reference",
    "section": "",
    "text": "main scripts that run the process\n\n\n\nhelpers\n\n\n\nazure\n\n\n\n\n\n\n\nfunctions for record matching\n\n\n\ndataframe_matcher",
    "crumbs": [
      "Reference",
      "Function reference"
    ]
  },
  {
    "objectID": "reference/index.html#functions",
    "href": "reference/index.html#functions",
    "title": "Function reference",
    "section": "",
    "text": "main scripts that run the process\n\n\n\nhelpers\n\n\n\nazure",
    "crumbs": [
      "Reference",
      "Function reference"
    ]
  },
  {
    "objectID": "reference/index.html#matching",
    "href": "reference/index.html#matching",
    "title": "Function reference",
    "section": "",
    "text": "functions for record matching\n\n\n\ndataframe_matcher",
    "crumbs": [
      "Reference",
      "Function reference"
    ]
  },
  {
    "objectID": "reference/dataframe_matcher.html",
    "href": "reference/dataframe_matcher.html",
    "title": "dataframe_matcher",
    "section": "",
    "text": "dataframe_matcher",
    "crumbs": [
      "Reference",
      "Matching",
      "dataframe_matcher"
    ]
  },
  {
    "objectID": "reference/dataframe_matcher.html#classes",
    "href": "reference/dataframe_matcher.html#classes",
    "title": "dataframe_matcher",
    "section": "Classes",
    "text": "Classes\n\n\n\nName\nDescription\n\n\n\n\nDataFrameMatcher\nA utility class for matching records.\n\n\n\n\nDataFrameMatcher\ndataframe_matcher.DataFrameMatcher(\n    self,\n    df_src: pl.DataFrame,\n    df_ref: pl.DataFrame,\n    first_name: str | tuple[str, str],\n    last_name: str | tuple[str, str],\n    dob: str | tuple[str, str],\n    spec_col_date: str | tuple[str, str],\n    key: str | list | None = None,\n    threshold: int | float = 80,\n    day_max: int | None = None,\n    business_day_max: int | None = None,\n)\nA utility class for matching records.\nThis class provides functionality to match submissions to cases (epi data) based on exact matching via accessions or fuzzy matching based on patient demographics\n\nParameters\n\ndf_src : pl.DataFrame\n\nSource dataframe containing any Key(s) and patient demographics.\n\ndf_ref : pl.DataFrame\n\nReference queried dataframe containing patient demographics.\n\nfirst_name : str | tuple[str, str]\n\nThe first name demographic column name in the source and reference dataframes. If the names are different, they should be provided in a tuple containing the source name first, followed by the reference name.\n\nlast_name : str | tuple[str, str]\n\nThe last name demographic column name in the source and reference dataframes. If the names are different, they should be provided in a tuple containing the source name first, followed by the reference name.\n\ndob : str | tuple[str, str]\n\nThe birth date demographic column name in the source and reference dataframes. If the names are different, they should be provided in a tuple containing the source name first, followed by the reference name.\n\nspec_col_date : str | tuple[str, str]\n\nThe specimen collection date column name in the source and reference dataframes. If the names are different, they should be provided in a tuple containing the source name first, followed by the reference name.\n\nkey : str | list | None = None\n\nThe key (or list of keys) which group to a distinct source record. Only one match can be returned per distinct key. If no key given, each row in the source df will be treated as a distinct record to be matched.\n\nthreshold : int | float = 80\n\nThe inclusive fuzzy scoring threshold used to filter fuzzy matches. Matches with a score at or above the threshold will be returned in the fuzzy matched object. Defaults to 80.\n\nday_max : int | None = None\n\nThe max number of days between reference and source specimen collection dates a fuzzy matched record can have and be returned as a match\n\nbusiness_day_max : int | None = None\n\nThe max number of business days between reference and source specimen collection dates a fuzzy matched record can have and be returned as a match. Business days are counted as weekdays (holidays are not accounted for).\n\n\n\n\nReturns\n\nfuzzy_matched_review : pl.DataFrame\n\nrecords that successfully fuzzy matched\n\nfuzzy_without_demo : pl.DataFrame\n\nrecords missing demographics and can’t be matched\n\nfuzzy_matched_none : pl.DataFrame\n\nrecords that did not have any match\n\nfuzzy_matched_roster : pl.DataFrame\n\nrecords that had an exact match to reference dataframe\n\n\n\n\nExamples\nStep 1: Import the packages:\n\nfrom wadoh_raccoon import dataframe_matcher as dfm\nimport polars as pl\nfrom datetime import date\n\nStep 2: The fuzzy matching functions need two dataframes to match. Bring your dataframe and the reference dataframe:\n\n# Create example data\nyour_df = pl.DataFrame({\n    'submission_number': [453278555, 453278555, 887730141],\n    'first_name': ['DAVIS', 'DAVIS', 'GRANT'],\n    'last_name': ['SMITHDAVIS', 'SMITHDAVIS', 'MITHCELL'],\n    'sub_collection_date': [date(2024, 11, 29), date(2024, 11, 29), date(2024, 12, 2)],\n    'birth_date': [date(1989, 7, 15), date(1989, 7, 15), date(1990, 6, 21)]\n})\n\nreference_df = pl.DataFrame({\n    'CASE_ID': [100000032, 100000041, 100020000],\n    'first_name_reference': ['DAVID', 'DAVID', 'TRASH'],\n    'last_name_reference': ['SMITDAVIS', 'SMITDAVIS', 'PANDA'],\n    'ref_collection_date': [date(2024, 11, 29), date(2024, 8, 31), date(2024, 8, 31)],\n    'birth_date': [date(1989, 7, 15), date(1989, 7, 15), date(1990, 6, 21)]\n})\n\nStep 3: Initalize the fuzzy matching class and input which dataframes and columns you are matching on\n\nfuzzy_init = dfm.DataFrameMatcher(\n    df_src=your_df,\n    df_ref=reference_df,\n    first_name=('first_name', 'first_name_reference'),\n    last_name=('last_name', 'last_name_reference'),\n    dob='birth_date',\n    spec_col_date=('sub_collection_date', 'ref_collection_date'),\n    key='submission_number',\n    threshold=80  # set what kind of fuzzy threshold you want, 100 being exact match\n)\n\nStep 4: Run fuzzy matching! This will output data on what matched and what didn’t match.\n\nresult = fuzzy_init.match()\n\nSuccess: No data leaks detected. Insert victory cigar\n0 exact matches\n1 fuzzy matched\n1 no match found\n0 records without demo\n\nTotal unique persons processed:  2 \nOriginal submissions to fuzzy (including no_match rematch attempt): 3\n\n\nYou can also examine the output dataframes by pulling them out of the result class, like this:\nresult.fuzzy_unmatched\n\n\n\n\n\n\n\n\nindex\nsubmission_number\nfirst_name\nlast_name\nsub_collection_date\nbirth_date\nfirst_name_clean\nlast_name_clean\nsubmitted_collection_date\nsubmitted_dob\nCASE_ID\nfirst_name_reference\nlast_name_reference\nref_collection_date\nbirth_date_right\nfirst_name_clean_right\nlast_name_clean_right\nreference_collection_date\nfirst_name_result\nlast_name_result\nreverse_first_name_result\nreverse_last_name_result\nmatch_ratio\nreverse_match_ratio\n\n\n\n\n0\n887730141\nGRANT\nMITHCELL\n2024-12-02\n1990-06-21\nGRANT\nMITHCELL\n2024-12-02\n1990-06-21\n100020000\nTRASH\nPANDA\n2024-08-31\n1990-06-21\nTRASH\nPANDA\n2024-08-31\n40\n0\n40\n31\n20.0\n35.5\n\n\n\n\n\n\n\n\nresult.fuzzy_matched\n\n\n\n\n\n\n\n\nindex\nsubmission_number\nfirst_name\nlast_name\nsub_collection_date\nbirth_date\nfirst_name_clean\nlast_name_clean\nsubmitted_collection_date\nsubmitted_dob\nCASE_ID\nfirst_name_reference\nlast_name_reference\nref_collection_date\nbirth_date_right\nfirst_name_clean_right\nlast_name_clean_right\nreference_collection_date\nfirst_name_result\nlast_name_result\nreverse_first_name_result\nreverse_last_name_result\nmatch_ratio\nreverse_match_ratio\nday_count\nbusiness_day_count\n\n\n\n\n0\n453278555\nDAVIS\nSMITHDAVIS\n2024-11-29\n1989-07-15\nDAVIS\nSMITHDAVIS\n2024-11-29\n1989-07-15\n100000032\nDAVID\nSMITDAVIS\n2024-11-29\n1989-07-15\nDAVID\nSMITDAVIS\n2024-11-29\n80\n95\n71\n53\n87.5\n62.0\n0\n0\n\n\n\n\n\n\n\n\n  \n\n\nMethods\n\n\n\nName\nDescription\n\n\n\n\nfuzzy_match\nWhere the magic happens. Do the fuzzy matching to the dataframe\n\n\n\n\nfuzzy_match\ndataframe_matcher.DataFrameMatcher.fuzzy_match(dob_match)\nWhere the magic happens. Do the fuzzy matching to the dataframe\n\nParameters\n\ndob_match : \n\nthe dataframe that has records grouped by their dob match\n\n\n\n\nReturns\n\nfuzzy_matched : pl.DataFrame\n\ndataframe with matches that met or exceeded the fuzzy matching score threshold\n\nfuzzy_unmatched : pl.DataFrame\n\ndataframe with matches that failed to meet the fuzzy matching score threshold\n\n\n\n\nExamples\nfrom wadoh_raccoon import dataframe_matcher as dfm\nimport polars as pl\nfrom datetime import date\n\n# Create example data\ndf = pl.DataFrame({\n    'submission_number': [453278555, 453278555, 887730141],\n    'first_name_clean': ['DAVIS', 'DAVIS', 'GRANT'],\n    'last_name_clean': ['SMITHDAVIS', 'SMITHDAVIS', 'MITHCELL'],\n    'submitted_collection_date': [date(2024, 11, 29), date(2024, 11, 29), date(2024, 12, 2)],\n    'submitted_dob': [date(1989, 7, 15), date(1989, 7, 15), date(1990, 6, 21)],\n     'CASE_ID': [100000032, 100000041, None],\n    'first_name_clean_right': ['DAVID', 'DAVID', None],\n    'last_name_clean_right': ['SMITDAVIS', 'SMITDAVIS', None],\n     'reference_collection_date': [date(2024, 11, 29), date(2024, 8, 31), None]\n})\n\n# Init dataframe matcher\n# (this is not how to use the instance but input data not used in this example)\ninstance = dfm.DataFrameMatcher(df, df)\nfuzzy_matched, fuzzy_unmatched = instance.fuzzy_match(dob_match=df)\nFuzzy match found:\nhelpers.gt_style(df_inp=fuzzy_matched)\nno matches found:\nhelpers.gt_style(df_inp=fuzzy_matched_none)",
    "crumbs": [
      "Reference",
      "Matching",
      "dataframe_matcher"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "wadoh_raccoon",
    "section": "",
    "text": "NORTHWEST PATHOGEN GENOMICS CENTER OF EXCELLENCE\n\n\nwadoh_raccoon python package\n\nA Python package for transforming and linking pathogen sequencing/subtyping metadata."
  },
  {
    "objectID": "index.html#installation",
    "href": "index.html#installation",
    "title": "wadoh_raccoon",
    "section": "Installation ",
    "text": "Installation \n\ninstallinstall specific version\n\n\nuv pip install git+https://github.com/NW-PaGe/wadoh_raccoon.git#egg=wadoh_raccoon\n\n\nTo install a specific version, find the git tag noted in the GitHub Release section (something like v0.2.5) and then put it in the install statement like .git@v0.2.5:\nuv pip install git+https://github.com/NW-PaGe/wadoh_raccoon.git@v0.2.5#egg=wadoh_raccoon"
  },
  {
    "objectID": "index.html#example-functions",
    "href": "index.html#example-functions",
    "title": "wadoh_raccoon",
    "section": "Example Functions ",
    "text": "Example Functions"
  },
  {
    "objectID": "index.html#try-it-yourself",
    "href": "index.html#try-it-yourself",
    "title": "wadoh_raccoon",
    "section": "Try It Yourself",
    "text": "Try It Yourself"
  },
  {
    "objectID": "index.html#api-reference",
    "href": "index.html#api-reference",
    "title": "wadoh_raccoon",
    "section": "API Reference ",
    "text": "API Reference \nreference"
  },
  {
    "objectID": "articles/index.html",
    "href": "articles/index.html",
    "title": "builds",
    "section": "",
    "text": "0.1.1 build\n0.4.0 build",
    "crumbs": [
      "Articles",
      "builds"
    ]
  },
  {
    "objectID": "reference/azure.html",
    "href": "reference/azure.html",
    "title": "azure",
    "section": "",
    "text": "wadoh_raccoon.utils.azure\n\n\n\n\n\nName\nDescription\n\n\n\n\n__delete\nDelete\n\n\nblob_delete\nBlob Delete\n\n\nblob_download\nDownloads a specific file from Azure Blob Storage to a local directory.\n\n\nblob_upload\nBlob Upload\n\n\n\n\n\nwadoh_raccoon.utils.azure.__delete(\n    client: ContainerClient,\n    blob_path: str,\n    recursive: bool = False,\n)\nDelete Deletes blobs from the specified directory in Azure Blob Storage.\n\n\nThis is a private function utilize by blob_delete and should not be called outside of that scope. This method can be used to upload a file from a local machine to Azure blob storage. This private helper method is designed to iterate through blobs within a given directory (blob_path) in Azure Blob Storage. It deletes blobs one by one, and if a subdirectory is found and the recursive flag is set to True, it continues the deletion process for that subdirectory.\n\n\n\n\nclient : ContainerClient\n\nThe Azure Blob Storage container client used to interact with the blob container.\n\nblob_path : str\n\nThe path to the directory (blob) to delete from. This can be a directory or a specific blob.\n\nrecursive : bool = False\n\nIf True, subdirectories within the blob_path will also be processed and deleted. Defaults to False.\n\n\n\n\n\n\nNone : \n\nThis method performs deletions and prints the results but does not return any value.\n\n\n\n\n\nfrom wadoh_raccoon.utils.azure import __delete\n\n# Delete a specific blob:\n__delete(client=container_client, blob_path=\"blob/to_delete/data.csv\")\n\n# Delete a blob from a directory and any blobs in subdirectories:\n__delete(client=container_client, blob_path=\"blob/to_delete\", recursive=True)\n\n\n\n\nwadoh_raccoon.utils.azure.blob_delete(\n    account: str,\n    container_name: str,\n    blob_path: str,\n    credential: TokenCredential = None,\n    recursive: bool = False,\n    account_is_url: bool = False,\n)\nBlob Delete Deletes a specific file or all files within a directory in Azure Blob Storage.\n\n\nThis method establishes a connection to the specified Azure Blob Storage container and deletes either a specific file or all files within a given directory. If the recursive flag is set to True, it will delete files from subdirectories as well.\n\n\n\n\naccount : str\n\nthe storage account name.\n\ncontainer_name : str\n\nthe storage container name.\n\nblob_path : str\n\nThe directory (or blob) path from which files are to be deleted. This should be a directory path if deleting multiple files.\n\ncredential : TokenCredential = None\n\nThe Azure credential used for authentication. Can be any implementation of azure.core.credentials.TokenCredential (e.g., DefaultAzureCredential, AzureCliCredential, ManagedIdentityCredential). Defaults to AzureCliCredential.\n\nrecursive : bool = False\n\nIf True, all files within subdirectories of blob_path will also be deleted. Defaults to False.\n\naccount_is_url : bool = False\n\nWhether account is supplied as a full URL instead of an account name. Account URLs will be set as the account endpoint as-is, and should be used for testing with Azurite, for example. Account names can be supplied with this flag set to False, and will be constructed to a full URL in the form of https://{account}.blob.core.windows.net. Defaults to False.\n\n\n\n\n\n\nNone : \n\nThis method deletes the specified file or directory contents and prints results, but does not return any value.\n\n\n\n\n\nfrom wadoh_raccoon.utils.azure import blob_delete\n\n# Delete a specific blob file:\nblob_delete(account=\"myaccount\",\n            container_name=\"mycontainer\",\n            blob_path=\"blob/to_delete/data.txt\")\n\n# Delete files within a directory and any files in subdirectories:\nblob_delete(account=\"myaccount\",\n            container_name=\"mycontainer\",\n            blob_path=\"blob/to_delete/\",\n            recursive=True)\n\n\n\n\nwadoh_raccoon.utils.azure.blob_download(\n    account: str,\n    container_name: str,\n    blob_path: str,\n    file_path: str,\n    credential: TokenCredential = None,\n    account_is_url: bool = False,\n)\nDownloads a specific file from Azure Blob Storage to a local directory.\n\n\nThis method authenticates with Azure using the Azure CLI, establishes a connection to the specified Azure Blob Storage container, and downloads a specific file from a given directory in Azure Blob Storage.\n\n\n\n\naccount : str\n\nThe storage account name.\n\ncontainer_name : str\n\nThe storage container name.\n\nblob_path : str\n\nThe blob path and name in Azure Blob Storage.\n\nfile_path : str\n\nThe local path and name where the file will be saved. The path must exist or will be created automatically.\n\ncredential : TokenCredential = None\n\nThe Azure credential used for authentication. Can be any implementation of azure.core.credentials.TokenCredential (e.g., DefaultAzureCredential, AzureCliCredential, ManagedIdentityCredential). Defaults to AzureCliCredential.\n\naccount_is_url : bool = False\n\nWhether account is supplied as a full URL instead of an account name. Account URLs will be set as the account endpoint as-is, and should be used for testing with Azurite, for example. Account names can be supplied with this flag set to False, and will be constructed to a full URL in the form of https://{account}.blob.core.windows.net. Defaults to False.\n\n\n\n\n\n\nNone : \n\nThis method downloads the specified file from Azure Blob Storage to the local machine and prints the result, but does not return any value.\n\n\n\n\n\nfrom wadoh_raccoon.utils.azure import blob_download\n\n# Download a specific file from Azure Blob Storage:\nblob_download(account=\"myaccount\",\n            container_name=\"mycontainer\",\n            blob_path=\"blob/to_download/data.json\",\n            file_path=\"data/data.json\")\n\n\n\n\nwadoh_raccoon.utils.azure.blob_upload(\n    account: str,\n    container_name: str,\n    blob_path: str,\n    file_path: str,\n    credential: TokenCredential = None,\n    overwrite: bool = True,\n    access_tier: str = None,\n    account_is_url: bool = False,\n)\nBlob Upload Uploads a local file to Azure Blob Storage.\n\n\nThis method can be used to upload a file from a specified local directory (file_path) into Azure blob storage at the specified blob location (blob_path).\n\n\n\n\naccount : str\n\nthe storage account name.\n\ncontainer_name : str\n\nthe storage container name.\n\nblob_path : str\n\nThe path and name of the blob to be created in Azure Blob Storage.\n\nfile_path : str\n\nThe path and name of the file to upload.\n\ncredential : TokenCredential = None\n\nThe Azure credential used for authentication. Can be any implementation of azure.core.credentials.TokenCredential (e.g., DefaultAzureCredential, AzureCliCredential, ManagedIdentityCredential). Defaults to AzureCliCredential.\n\noverwrite : bool = True\n\nWhether blobs should be overwritten if they exist. Defaults to True.\n\naccess_tier : str = None\n\nThe access tier for the blob (‘Hot’, ‘Cool’, ‘Cold’ or ‘Archive’). Defaults to container’s default access tier.\n\naccount_is_url : bool = False\n\nWhether account is supplied as a full URL instead of an account name. Account URLs will be set as the account endpoint as-is, and should be used for testing with Azurite, for example. Account names can be supplied with this flag set to False, and will be constructed to a full URL in the form of https://{account}.blob.core.windows.net. Defaults to False.\n\n\n\n\n\n\nNone : \n\nThis method uploads the specified file to Azure Blob Storage and prints the result. No value is returned.\n\n\n\n\n\nfrom wadoh_raccoon.utils.azure import blob_upload\n\n# Upload a file from a local directory to the blob storage:\nblob_upload(\n    account=\"mystorageaccount\",\n    container_name=\"mycontainer\",\n    file_path=\"data.csv\",\n    blob_path=\"myblob/blob_data.csv\"\n)",
    "crumbs": [
      "Reference",
      "Functions",
      "azure"
    ]
  },
  {
    "objectID": "reference/azure.html#functions",
    "href": "reference/azure.html#functions",
    "title": "azure",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\n__delete\nDelete\n\n\nblob_delete\nBlob Delete\n\n\nblob_download\nDownloads a specific file from Azure Blob Storage to a local directory.\n\n\nblob_upload\nBlob Upload\n\n\n\n\n\nwadoh_raccoon.utils.azure.__delete(\n    client: ContainerClient,\n    blob_path: str,\n    recursive: bool = False,\n)\nDelete Deletes blobs from the specified directory in Azure Blob Storage.\n\n\nThis is a private function utilize by blob_delete and should not be called outside of that scope. This method can be used to upload a file from a local machine to Azure blob storage. This private helper method is designed to iterate through blobs within a given directory (blob_path) in Azure Blob Storage. It deletes blobs one by one, and if a subdirectory is found and the recursive flag is set to True, it continues the deletion process for that subdirectory.\n\n\n\n\nclient : ContainerClient\n\nThe Azure Blob Storage container client used to interact with the blob container.\n\nblob_path : str\n\nThe path to the directory (blob) to delete from. This can be a directory or a specific blob.\n\nrecursive : bool = False\n\nIf True, subdirectories within the blob_path will also be processed and deleted. Defaults to False.\n\n\n\n\n\n\nNone : \n\nThis method performs deletions and prints the results but does not return any value.\n\n\n\n\n\nfrom wadoh_raccoon.utils.azure import __delete\n\n# Delete a specific blob:\n__delete(client=container_client, blob_path=\"blob/to_delete/data.csv\")\n\n# Delete a blob from a directory and any blobs in subdirectories:\n__delete(client=container_client, blob_path=\"blob/to_delete\", recursive=True)\n\n\n\n\nwadoh_raccoon.utils.azure.blob_delete(\n    account: str,\n    container_name: str,\n    blob_path: str,\n    credential: TokenCredential = None,\n    recursive: bool = False,\n    account_is_url: bool = False,\n)\nBlob Delete Deletes a specific file or all files within a directory in Azure Blob Storage.\n\n\nThis method establishes a connection to the specified Azure Blob Storage container and deletes either a specific file or all files within a given directory. If the recursive flag is set to True, it will delete files from subdirectories as well.\n\n\n\n\naccount : str\n\nthe storage account name.\n\ncontainer_name : str\n\nthe storage container name.\n\nblob_path : str\n\nThe directory (or blob) path from which files are to be deleted. This should be a directory path if deleting multiple files.\n\ncredential : TokenCredential = None\n\nThe Azure credential used for authentication. Can be any implementation of azure.core.credentials.TokenCredential (e.g., DefaultAzureCredential, AzureCliCredential, ManagedIdentityCredential). Defaults to AzureCliCredential.\n\nrecursive : bool = False\n\nIf True, all files within subdirectories of blob_path will also be deleted. Defaults to False.\n\naccount_is_url : bool = False\n\nWhether account is supplied as a full URL instead of an account name. Account URLs will be set as the account endpoint as-is, and should be used for testing with Azurite, for example. Account names can be supplied with this flag set to False, and will be constructed to a full URL in the form of https://{account}.blob.core.windows.net. Defaults to False.\n\n\n\n\n\n\nNone : \n\nThis method deletes the specified file or directory contents and prints results, but does not return any value.\n\n\n\n\n\nfrom wadoh_raccoon.utils.azure import blob_delete\n\n# Delete a specific blob file:\nblob_delete(account=\"myaccount\",\n            container_name=\"mycontainer\",\n            blob_path=\"blob/to_delete/data.txt\")\n\n# Delete files within a directory and any files in subdirectories:\nblob_delete(account=\"myaccount\",\n            container_name=\"mycontainer\",\n            blob_path=\"blob/to_delete/\",\n            recursive=True)\n\n\n\n\nwadoh_raccoon.utils.azure.blob_download(\n    account: str,\n    container_name: str,\n    blob_path: str,\n    file_path: str,\n    credential: TokenCredential = None,\n    account_is_url: bool = False,\n)\nDownloads a specific file from Azure Blob Storage to a local directory.\n\n\nThis method authenticates with Azure using the Azure CLI, establishes a connection to the specified Azure Blob Storage container, and downloads a specific file from a given directory in Azure Blob Storage.\n\n\n\n\naccount : str\n\nThe storage account name.\n\ncontainer_name : str\n\nThe storage container name.\n\nblob_path : str\n\nThe blob path and name in Azure Blob Storage.\n\nfile_path : str\n\nThe local path and name where the file will be saved. The path must exist or will be created automatically.\n\ncredential : TokenCredential = None\n\nThe Azure credential used for authentication. Can be any implementation of azure.core.credentials.TokenCredential (e.g., DefaultAzureCredential, AzureCliCredential, ManagedIdentityCredential). Defaults to AzureCliCredential.\n\naccount_is_url : bool = False\n\nWhether account is supplied as a full URL instead of an account name. Account URLs will be set as the account endpoint as-is, and should be used for testing with Azurite, for example. Account names can be supplied with this flag set to False, and will be constructed to a full URL in the form of https://{account}.blob.core.windows.net. Defaults to False.\n\n\n\n\n\n\nNone : \n\nThis method downloads the specified file from Azure Blob Storage to the local machine and prints the result, but does not return any value.\n\n\n\n\n\nfrom wadoh_raccoon.utils.azure import blob_download\n\n# Download a specific file from Azure Blob Storage:\nblob_download(account=\"myaccount\",\n            container_name=\"mycontainer\",\n            blob_path=\"blob/to_download/data.json\",\n            file_path=\"data/data.json\")\n\n\n\n\nwadoh_raccoon.utils.azure.blob_upload(\n    account: str,\n    container_name: str,\n    blob_path: str,\n    file_path: str,\n    credential: TokenCredential = None,\n    overwrite: bool = True,\n    access_tier: str = None,\n    account_is_url: bool = False,\n)\nBlob Upload Uploads a local file to Azure Blob Storage.\n\n\nThis method can be used to upload a file from a specified local directory (file_path) into Azure blob storage at the specified blob location (blob_path).\n\n\n\n\naccount : str\n\nthe storage account name.\n\ncontainer_name : str\n\nthe storage container name.\n\nblob_path : str\n\nThe path and name of the blob to be created in Azure Blob Storage.\n\nfile_path : str\n\nThe path and name of the file to upload.\n\ncredential : TokenCredential = None\n\nThe Azure credential used for authentication. Can be any implementation of azure.core.credentials.TokenCredential (e.g., DefaultAzureCredential, AzureCliCredential, ManagedIdentityCredential). Defaults to AzureCliCredential.\n\noverwrite : bool = True\n\nWhether blobs should be overwritten if they exist. Defaults to True.\n\naccess_tier : str = None\n\nThe access tier for the blob (‘Hot’, ‘Cool’, ‘Cold’ or ‘Archive’). Defaults to container’s default access tier.\n\naccount_is_url : bool = False\n\nWhether account is supplied as a full URL instead of an account name. Account URLs will be set as the account endpoint as-is, and should be used for testing with Azurite, for example. Account names can be supplied with this flag set to False, and will be constructed to a full URL in the form of https://{account}.blob.core.windows.net. Defaults to False.\n\n\n\n\n\n\nNone : \n\nThis method uploads the specified file to Azure Blob Storage and prints the result. No value is returned.\n\n\n\n\n\nfrom wadoh_raccoon.utils.azure import blob_upload\n\n# Upload a file from a local directory to the blob storage:\nblob_upload(\n    account=\"mystorageaccount\",\n    container_name=\"mycontainer\",\n    file_path=\"data.csv\",\n    blob_path=\"myblob/blob_data.csv\"\n)",
    "crumbs": [
      "Reference",
      "Functions",
      "azure"
    ]
  },
  {
    "objectID": "reference/helpers.html",
    "href": "reference/helpers.html",
    "title": "helpers",
    "section": "",
    "text": "wadoh_raccoon.utils.helpers",
    "crumbs": [
      "Reference",
      "Functions",
      "helpers"
    ]
  },
  {
    "objectID": "reference/helpers.html#functions",
    "href": "reference/helpers.html#functions",
    "title": "helpers",
    "section": "Functions",
    "text": "Functions\n\n\n\nName\nDescription\n\n\n\n\nclean_name\nClean name field by stripping non-alpha characters and converting to uppercase.\n\n\ndate_format\nFormat Dates\n\n\nget_secrets\nGet secrets\n\n\ngt_style\nStyle for GT Tables\n\n\nlazy_height\nOutput the height of a polars frame regardless of it being lazy or eager\n\n\nmft_upload\nUpload files to Washington State MFT server\n\n\nsave_raw_values\nsave raw values\n\n\n\n\nclean_name\nwadoh_raccoon.utils.helpers.clean_name(col: str)\nClean name field by stripping non-alpha characters and converting to uppercase.\n\nParameters\n\ncol : str\n\nName of column to clean\n\n\n\n\nReturns\n\n : pl.Expr:\n\na column of uppercase, non-alpha character, non-whitespace strings\n\n\n\n\nExamples\n\nimport polars as pl\nfrom wadoh_raccoon.utils import helpers\n\ndf = pl.DataFrame({\n    \"name\": [\n        \"A$AP rocky\",\n        \"50 cent\",\n        \"sTevIe WoNdEr\"\n    ]\n})\n\noutput = df.with_columns(helpers.clean_name(\"name\").alias(\"clean_name\"))\n\nhelpers.gt_style(df_inp=output)\n\n\n\n\n\n\n\nindex\nname\nclean_name\n\n\n\n\n0\nA$AP rocky\nAAPROCKY\n\n\n1\n50 cent\nCENT\n\n\n2\nsTevIe WoNdEr\nSTEVIEWONDER\n\n\n\n\n\n\n\n\n\n\n\ndate_format\nwadoh_raccoon.utils.helpers.date_format(\n    df: pl.DataFrame | pl.LazyFrame,\n    col: str,\n)\nFormat Dates\nConvert string dates into a yyyy-mm-dd format. The function uses pl.coalesce to try to process different formats. For example, it will first try to convert m/d/y, and then if that doesn’t work it will try d/m/y. It’s not perfect, but if someone messes up the date it’s their fault.\nNote: it won’t attempt to convert excel dates. If someone sends us excel dates we will file a lawsuit.\n\nUsage\nTo be applied to a string date column.\n\n\nParameters\n\ndf : pl.DataFrame | pl.LazyFrame\n\na polars dataframe (needed to check if col is pl.Date type or not)\n\ncol : str\n\na string column that has a date\n\n\n\n\nReturns\n\n : pl.Expr:\n\na date column\n\n\n\n\nExamples\n\nimport polars as pl\nfrom wadoh_raccoon.utils import helpers\n\ndf = pl.DataFrame({\n    \"dates\": [\n        \"2024-10-30\",     # ISO format\n        \"30/10/2024\",     # European format\n        \"10/20/2024\",     # US format\n        \"10-30-2024\",     # US format\n        \"October 30, 2024\",  # Full month name format,\n        \"45496\",           # an excel date LOL\n        \"2022-12-27 08:26:49\"\n    ]\n})\n\noutput = (\n    df\n    .with_columns(\n        new_date=helpers.date_format(df=df,col='dates')\n    )\n)\n\nhelpers.gt_style(df_inp=output)\n\n\n\n\n\n\n\nindex\ndates\nnew_date\n\n\n\n\n0\n2024-10-30\n2024-10-30\n\n\n1\n30/10/2024\n2024-10-30\n\n\n2\n10/20/2024\n2024-10-20\n\n\n3\n10-30-2024\n2024-10-30\n\n\n4\nOctober 30, 2024\n2024-10-30\n\n\n5\n45496\nNone\n\n\n6\n2022-12-27 08:26:49\n2022-12-27\n\n\n\n\n\n\n\n\n\n\n\nget_secrets\nwadoh_raccoon.utils.helpers.get_secrets(vault, keys)\nGet secrets\nRetrieve secrets from Azure KeyVault. This function will utilize the keys that are passed to retrieve the corresponding secrets.\n**Note: Authenication takes place via DefaultAzureCredential which attempts multiple authentication methods. One method is checking against Azure CLI if logged in.\n\nUsage\nUse this function to securely retrieve secret values from Azure KeyVault using the specified key(s). The function accepts either a single key or multiple keys as a list.\n\n\nParameters\n\nvault : \n\nKey vault url.\n\nkeys : \n\nA single secret key or list of secret keys.\n\n\n\n\nReturns\n\n : str or tuple of str\n\nIf a single key is provided, returns the secret value as a string. If a list of keys is provided, returns a tuple of secret values in the same order.\n\n\n\n\nExamples\nfrom wadoh_raccoon.utils import helpers\n\n# Get a single secret\ndb_password = helpers.get_secrets(\"keyvault_url\", \"db-password\")\n\n# Get multiple secrets at once\nusername, password, api_key = helpers.get_secrets(\n    \"keyvault_url\",\n    [\"db-username\", \"db-password\", \"api-key\"]\n)\n\n\n\ngt_style\nwadoh_raccoon.utils.helpers.gt_style(\n    df_inp: pl.DataFrame,\n    title: str = '',\n    subtitle: str = '',\n    add_striping_inp,\n    index_inp,\n)\nStyle for GT Tables\n\nUsage\nApply this style to a Polars DataFrame\n\n\nParameters\n\ndf_inp : pl.DataFrame\n\na polars dataframe\n\ntitle : str = ''\n\na title for the table (optional)\n\nsubtitle : str = ''\n\na subtitle for the table (optional, must have a title if using a subtitle)\n\nadd_striping_inp :  = True\n\nstriping in the table True or False\n\nindex_inp :  = True\n\nadd a column for the row number and label it index\n\n\n\n\nReturns\n\n : GT\n\na GT object (great_tables table)\n\n\n\n\nExamples\n\nimport polars as pl\nfrom wadoh_raccoon.utils import helpers\ndf = pl.DataFrame({\n    \"x\": [1,1,2],\n    \"y\": [1,2,3]\n})\n\nA table with a title/subtitle:\n\nhelpers.gt_style(df_inp=df,title=\"My Title\",subtitle=\"My Subtitle\")\n\n\n\n\n\n\n\nMy Title\n\n\nMy Subtitle\n\n\nindex\nx\ny\n\n\n\n\n0\n1\n1\n\n\n1\n1\n2\n\n\n2\n2\n3\n\n\n\n\n\n\n\n\nNo title/subtitle\n\nhelpers.gt_style(df_inp=df)\n\n\n\n\n\n\n\nindex\nx\ny\n\n\n\n\n0\n1\n1\n\n\n1\n1\n2\n\n\n2\n2\n3\n\n\n\n\n\n\n\n\nWithout an index:\n\nhelpers.gt_style(df_inp=df,index_inp=False)\n\n\n\n\n\n\n\nx\ny\n\n\n\n\n1\n1\n\n\n1\n2\n\n\n2\n3\n\n\n\n\n\n\n\n\nWithout striping:\n\nhelpers.gt_style(df_inp=df,add_striping_inp=False)\n\n\n\n\n\n\n\nindex\nx\ny\n\n\n\n\n0\n1\n1\n\n\n1\n1\n2\n\n\n2\n2\n3\n\n\n\n\n\n\n\n\n\n\n\nlazy_height\nwadoh_raccoon.utils.helpers.lazy_height(lf: pl.DataFrame | pl.LazyFrame)\nOutput the height of a polars frame regardless of it being lazy or eager\n\n\nmft_upload\nwadoh_raccoon.utils.helpers.mft_upload(\n    upload: pl.DataFrame,\n    dir: str,\n    upload_file_name: str,\n    upload_file_extension: str,\n    username: str,\n    password: str,\n    host: str = 'mft.wa.gov',\n)\nUpload files to Washington State MFT server\nUpload Polars DataFrames to the Washington State Managed File Transfer (MFT) server via SFTP. This function converts DataFrames to various file formats and securely transfers them to specified directories on the MFT server.\n**Note: Authentication requires explicit credentials to be provided. The function automatically adds the server’s host key for simplified connection handling.\n\nUsage\nUse this function to upload processed surveillance data, reports, or other DataFrames to the MFT server for sharing with partners. The function handles file format conversion.\n\n\nParameters\n\nupload : polars.DataFrame\n\nThe Polars DataFrame to upload.\n\ndir : str\n\nTarget directory path on the MFT server (e.g., ‘/outbound/partner’).\n\nupload_file_name : str\n\nName of the file without extension (e.g., ‘surveillance_report’).\n\nupload_file_extension : str\n\nFile extension including the dot. Supported formats: ‘.csv’, ‘.xlsx’, ‘.json’, ‘.parquet’.\n\nusername : str\n\nMFT server username.\n\npassword : str\n\nMFT server password.\n\nhost : str = 'mft.wa.gov'\n\nMFT server hostname. Default is ‘mft.wa.gov’.\n\n\n\n\nReturns\n\n : None\n\nFiles are uploaded directly to the MFT server. Success message printed.\n\n\n\n\nRaises\n\n: TypeError\n\nIf upload is not a Polars DataFrame.\n\n: ValueError\n\nIf upload is empty, required parameters are missing, or upload_file_extension is not supported.\n\n: OSError\n\nIf the target directory does not exist or cannot be accessed on the MFT server.\n\n: ConnectionError\n\nIf SFTP connection fails.\n\n\n\n\nExamples\nimport polars as pl\nfrom wadoh_raccoon.utils.helpers import mft_upload, get_secrets\n\n# Create sample DataFrame\ndf = pl.DataFrame({\n    'case_id': [1, 2, 3],\n    'pathogen': ['Salmonella', 'E. coli', 'Campylobacter']\n})\n\n# Get credentials from Key Vault\nmft_user, mft_pass = get_secrets(\n    'vault_url', \n    ['mft-username', 'mft-password']\n)\n\n# Upload as CSV\nmft_upload(\n    upload=df,\n    dir='DEV_TESTING',\n    upload_file_name='weekly_report_2024_01',\n    upload_file_extension='.csv',\n    username=mft_user,\n    password=mft_pass\n)\n\n# Upload as Excel\nmft_upload(\n    upload=df,\n    dir='DEV_TESTING',\n    upload_file_name='weekly_report_2024_01',\n    upload_file_extension='.xlsx',\n    username=mft_user,\n    password=mft_pass\n)\n\n\n\nsave_raw_values\nwadoh_raccoon.utils.helpers.save_raw_values(\n    df_inp: pl.DataFrame,\n    primary_key_col: str,\n)\nsave raw values\n\nUsage\nConverts a polars dataframe into a dataframe with all columns in a struct column. It’s good for saving raw outputs of data.\n\n\nParameters\n\ndf_inp : pl.DataFrame\n\na polars dataframe\n\nprimary_key_col : str\n\ncolumn name for the primary key (submission key, not person/case key)\n\n\n\n\nReturns\n\ndf : pl.DataFrame\n\na dataframe\n\n\n\n\nExamples\n\nimport polars as pl\nfrom wadoh_raccoon.utils import helpers\n\ndata = pl.DataFrame({\n    \"lab_name\": [\"PHL\", \"MFT\", \"ELR\",\"PHL\"],\n    \"first_name\": [\"Alice\", \"Bob\", \"Charlie\", \"Charlie\"],\n    \"last_name\": [\"Smith\", \"Johnson\", \"Williams\", \"Williams\"],\n    \"WA_ID\": [1,2,4,4]\n})\n\nreceived_submissions_df = (\n        helpers.save_raw_values(df_inp=data,primary_key_col=\"WA_ID\")\n)\n\nhelpers.gt_style(data)\n\n\n\n\n\n\n\nindex\nlab_name\nfirst_name\nlast_name\nWA_ID\n\n\n\n\n0\nPHL\nAlice\nSmith\n1\n\n\n1\nMFT\nBob\nJohnson\n2\n\n\n2\nELR\nCharlie\nWilliams\n4\n\n\n3\nPHL\nCharlie\nWilliams\n4\n\n\n\n\n\n\n\n\n\nhelpers.gt_style(received_submissions_df)\n\n\n\n\n\n\n\nindex\nsubmission_number\ninternal_create_date\nraw_inbound_submission\n\n\n\n\n0\n1\n2026-02-04\n{\"PHL\",\"Alice\",\"Smith\",1}\n\n\n1\n2\n2026-02-04\n{\"MFT\",\"Bob\",\"Johnson\",2}\n\n\n2\n4\n2026-02-04\n{\"ELR\",\"Charlie\",\"Williams\",4}\n\n\n3\n4\n2026-02-04\n{\"PHL\",\"Charlie\",\"Williams\",4}",
    "crumbs": [
      "Reference",
      "Functions",
      "helpers"
    ]
  }
]